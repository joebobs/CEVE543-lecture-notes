---
title: "Lecture Notes Draft"
subtitle: "Diffusion Models for weather extremes prediction"
author: Joe Bobby, Andrew Bierbower
date: 2025-11-24
type: "lecture notes"
module: 1
week: 1
topics: ["Julia installation", "GitHub workflow", "Quarto basics"]
objectives:
  - "Show the working principle of diffusion models"
  - "Explore applications of Diffusion models"
ps_connection: "We attempt to show the utility of using Diffusion models for applications in weather inpainting and in temperature-precipitation modeling"

engine: julia
julia:
  exeflags: ["+1.11"] # ensures version 1.11

format:
  html:
    toc: true
    toc-depth: 2
    code-block-bg: "#f8f8f8"
    code-block-border-left: "#e1e4e5"
    theme: simplex
    number-sections: true
    fig-format: svg
    code-annotations: hover
    code-line-numbers: true
    date-format: "ddd., MMM. D"
  typst:
    fontsize: 11pt
    margin: 
      x: 1in
      y: 1in
    number-sections: true
    fig-format: svg
    code-line-numbers: true
    footer: "{{< meta author >}}"
    date-format: "ddd., MMM. D"

execute: 
  cache: true

# Code formatting options
code-overflow: wrap
code-line-numbers: true
code-block-font-size: "0.85em"
---

## The Basics of Diffusion Modeling

Diffusion models are a class of generative deep learning models (like GANs or VAEs), but function differently. They are probabilistic and model the entire distribution of possible outcomes, allowing for the generation of diverse, physically plausible realizations.

They way they work is through the combination of a forward and backward process that destroys and created information respectively.

Forward Process (Destroying information): Imagine taking a clear image (or climate map) and slowly adding Gaussian noise over many steps until it becomes pure static (random noise).

Reverse Process (Creating Information): The neural network learns to reverse this process. It starts with pure noise and iteratively denoises it to reconstruct a plausible sample from the data distribution.

## Forward Diffusion Formula in Quarto

The noisy data at each of the forward steps can be modelled using a stochastic noising process. The equation describing the noisy data at time step $t$, $\mathbf{x}_t$, in terms of the original data, $\mathbf{x}_0$, and added noise, $\boldsymbol{\epsilon}$, is given by:

$$
\mathbf{x}_t = \sqrt{\bar{\alpha}_t} \cdot \mathbf{x}_0 + \sqrt{1 - \bar{\alpha}_t} \cdot \boldsymbol{\epsilon}
$$

### Key Variables

* **$\mathbf{x}_t$**: The **noisy data** at time step $t$ (what the model sees during training).
* **$\mathbf{x}_0$**: The **original, clean data** (the *signal*, e.g., the original daily temperature map).
* **$\boldsymbol{\epsilon}$**: The **random noise** added (pure static), typically sampled from a standard normal distribution.
* **$\bar{\alpha}_t$** (read as **alpha-bar sub $t$**): A **schedule value** between 0 and 1. It controls the **signal-to-noise ratio**. As $t$ increases (more steps of diffusion), $\bar{\alpha}_t$ **decreases**, resulting in less signal and more noise in $\mathbf{x}_t$.

## The Reverse Process (Denoising)

The **reverse process** is the **learning objective** of the diffusion model. The neural network, often a U-Net architecture, is trained to iteratively *undo* the noise added during the forward process. This approach makes sense because after the model has trained, given a completely noisy image, the reverse process has the ability to **sample the distribution of the domain** learnt by the model.

It trains by trying to **predict the noise ($\boldsymbol{\epsilon}$)** that was added to $\mathbf{x}_0$ to create $\mathbf{x}_t$. If it can predict the noise perfectly, it can subtract it from $\mathbf{x}_t$ to reveal the clean, original image ($\mathbf{x}_0$).

---

### Loss Function (Mean Squared Error)

The model's training objective is minimized using the following simple $\mathbf{L_2}$ loss function (Mean Squared Error), which measures the difference between the true noise and the predicted noise.

$$
\text{Loss} = || \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, t) ||^2
$$

### Key Variables in the Loss

* **$\boldsymbol{\epsilon}$**: The **actual noise** that was added (the **ground truth**).
* **$\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_t, t)$**: The neural network's **prediction** of the noise, where $\theta$ represents the network's trainable parameters, and the prediction depends on the noisy data $\mathbf{x}_t$ and the time step $t$.
* **$|| \ldots ||^2$**: This is the **squared $\mathbf{L_2}$ norm** (Mean Squared Error). It calculates the square of the difference between the actual noise and the predicted noise across all dimensions (pixels/features). The model aims to drive this loss value **as close to zero as possible**.

## Comparison with Generative Adversarial Networks (GANs)

To understand why diffusion models have become the standard for high-fidelity generation, it is helpful to contrast them with the previous dominant architecture: GANs.

While diffusion models are **iterative sculptors** (slowly removing noise), GANs operate as a **forgery game** between two competing networks:
1.  **The Generator:** Creates fake data to fool the discriminator.
2.  **The Discriminator:** Tries to classify data as real or fake.

| Feature | GANs (Adversarial) | Diffusion Models (Iterative) |
| :--- | :--- | :--- |
| **Mechanism** | Min-max game between two networks | Single network learning to reverse noise |
| **Training Stability** | **Unstable**: Prone to "mode collapse" (generating the same image repeatedly) | **Stable**: Simple convex loss function (MSE) |
| **Diversity** | Low: Often ignores rare edge cases | **High**: Captures the full distribution (critical for weather extremes) |
| **Sampling Speed** | Fast (One step) | Slow (Many denoising steps) |

## Case Study: DiffESM (Bassetti et al., 2024)

In the context of this module, we examine *DiffESM: Conditional Emulation of Temperature and Precipitation in Earth System Models*. This paper demonstrates how diffusion models can be applied to **statistical downscaling** in climate science.

### The Problem: Computational Cost
Earth System Models (ESMs) rely on complex physics simulations (fluid dynamics, thermodynamics) that are computationally expensive. Running an ESM to simulate 100 years of daily weather for many different scenarios is often unfeasible. Existing cheap emulators often only output **monthly averages**, missing the "tails" of the distributionâ€”extreme events like heat waves or dry spells.

### The Solution: Conditional 3D Diffusion
DiffESM uses a diffusion model to "super-resolve" time. It takes a low-resolution input (Monthly Mean) and generates a high-resolution output (Daily Sequence).

#### 1. Architecture: The 3D U-Net
Unlike standard image diffusion (which is 2D), DiffESM uses a **3D U-Net** to handle the temporal dimension.
* **Dimensions:** $T \times H \times W$ (Time $\times$ Latitude $\times$ Longitude).
* **Input:** A block of random Gaussian noise ($x_T$) representing 28 days of data.
* **Conditioning ($c$):** The model is conditioned on the **Monthly Mean Map**. This map is concatenated to the noisy input at every step of the reverse process.

#### 2. The Denoising "Physics"
The model learns to transition from a **Random Distribution** (Gaussian noise) to a **Domain Distribution** (Physically plausible weather).
* **Step 1:** The model sees 3D static.
* **Step 500:** Vague structures appear. The model ensures spatial correlations (a storm spans multiple pixels).
* **Step 1000:** A sharp, daily weather sequence emerges.
* **Constraint:** Because of the conditioning ($c$), the average of the generated daily sequence mathematically aligns with the monthly mean provided.

### Evaluating Extremes
The authors tested DiffESM not just on pixel accuracy, but on its ability to replicate climate physics extremes using **Held-Out (HO)** sets:
1.  **Kolmogorov-Smirnov (KS) Test:** Verifying the full distribution of values matches real ESMs.
2.  **Temporal Metrics:** The model successfully reproduced **Hot Streaks** (consecutive hot days) and **Dry Spells** (consecutive days <1mm rain).
3.  **Intensity:** It captured the **SDII** (Simple Precipitation Intensity Index), proving it generates intense storms rather than just constant drizzle.

This demonstrates that diffusion models do not just "memorize" images; they learn the underlying **spatiotemporal statistics** of the physical system.
